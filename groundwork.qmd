---
title: Can sparse Bayesian independent component analysis describe gene regulation?
jupyter: python3
bibliography: bibliography.bib
reference-location: margin
format:
  html:
    standalone: true
    toc: true
  docx: default
---

We think we could use a sparse Bayesian independent component analysis model to
describe gene regulation in *E. coli* and other organisms for which there is
RNA sequencing data. This document explains why we think this, how we would
like do it and where we need help.

# Background

## Introduction

Living cells respond to environmental changes by up- or down-regulating their
genes, thereby changing the proportion in which the cell produces proteins,
which in turn alters the cell's behaviour. For example, a cell that moves into
a toxic environment might alter its gene expression so as to increase
production of a protein that exports the toxin or to decrease toxin-importing
proteins.

By analysing RNA transcripts it is possible to measure gene expression and see
how it varies across conditions.  There is now so much transcriptomics data
available that it plauibly contains sufficient information to learn how some
organisms orchestrate their gene regulation.
@tanIndependentComponentAnalysis2020 achieved this goal using a method based on
independent component analysis or ICA, leading to the development of the
concept of an Imodulon. 

## Imodulons

An Imodulon is a hypothetical latent allocation of weights to a subset of genes
derived from the results of an analysis involving ICA, that is taken to
represent a way that a cell can regulate its genes in response to changing
conditions. For example, suppose a certain Imodulon I1 regulates just two genes
G1 and G2 with respective weights 0.5 and -0.5. When I1 is activated, G1 will
be up-regulated and G2 will be down-regulated by the same amount. In contrast,
when I1 is deactivated, the opposite regulation will occur. It is typically
presumed that there are far fewer Imodulons than genes, that an Imodulon will
substantially up- or down-regulate the genes that it affects, and that most
Imodulons will affect a relatively small number of genes.

It is plausible that Imodulons roughly describe how gene regulation works
because of the known existence of transcription units, transcription factors
and regulons. Transcription units are sets of genes that share an RNA binding
site and can therefore only be regulated together. Transcription factors are
proteins that activate or deactivate particular transcription units. Regulons
are sets of genes that are regulated by exactl the same transcription factors.
Since there are known to be many of all these things, it is likely that a
latent representation like Imodulons is roughly correct. In particular, based
on the [regulonDB](https://regulondb.ccg.unam.mx/index.jsp) it is clear that
most transcription factors affect a small number of genes and that there are
fewer transcription factors than genes.^[Note that Imodulons are not the same
as transcription factors!]

Whereas previous analyses have attempted to fit ICA models using an approach
based on optimisation, we would like to fit a Bayesian statistical model that
implements ICA. We would like our statistical model to include an explicit
representation of the assumptions about Imodulon sparsity outlined above.

## Independent Component Analysis

Independent component analysis assumes that the numbers comprising an $I\times
J$ matrix of observations $X$ are generated by taking weighted sums of a known
number $K < J$ independent component vectors, as shown below: ^[Term names
chosen for consistency with the Imodulon papers]

$$
\begin{equation}
  x_{ij}=\sum_{k=1}^{K} m_{ik}a_{kj}
\end{equation}
$${#eq-ica-long}

or in matrix notation

$$
\begin{equation}
X = MA 
\end{equation}
$${#eq-ica}

It is assumed that the columns of the matrix $A$ are column-wise
probabilistically independent, so that the probability of the $j$th column of
$A$ is the product of the $K$ marginal probabilities, i.e. $p(a_{:j}) =
\prod_{k=1}^I p(a_{kj})$. Secondly, it is also assumed that the rows of $A$
have non-Gaussian marginal distributions. See
@hyvarinenIndependentComponentAnalysis2000 for a discussion of an optimisation
based approach to Independent component analysis and
@robertsBayesianIndependentComponent2005 for a discussion of Bayesian
independent component analysis.

In the canonical application of ICA each row of $X$ represents a time course of
signals from a receiver detecting input from $k$ sources; each row of $A$
represents the time course of signals from a source; each column of $M$
represents how a source mixes between receivers. In the context of a
transcriptomics data analysis the observation units are genes rather than
receivers, the observation rows represent separate experiments rather than time
courses and the columns of the matrix $M$ represents proto-Imodulons, i.e.
mixing weights for each gene for each proto-Imodulon. A separate downstream
analysis is required in order to sparsify the results by removing genes from
Imodulons and discarding some candidate Imodulons.

The Python library Scikit learn provides access to [an implementation of ICA
](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.FastICA.html)
based on minimsation of mutual information, as outlined in
@hyvarinenIndependentComponentAnalysis2000.

## Transcriptomics data 

The [precise-db](https://github.com/SBRG/precise-db) provides a large
collection of RNA sequencing data that can be used to create suitable input for independent
component analysis.

Like with other RNA sequencing data, each gene expression measurement in
precise-db starts as a count of the number of times an mRNA fragment that maps
to the gene was detected in the experiment fragments per transcript.
Unfortunately such counts are not comparable between genes within a sample
because they are sensitive to the size of the mRNA fragment that encodes the
gene (a big gene will tend to be counted more often than an equally expressed
small gene). Raw counts are also not comparable between samples because of
potential variations in sequence depth (i.e. the total number of measurements
from the sample) and the mRNA-fragment-to-gene map used. Consequently the usual
practice is to transform raw counts by first normalising based on the gene size
and then 'proportionising', ending with a relative unit called transcripts per
million or TPM:

$$
\begin{equation}
TPM(g) = \frac{count(g)/size(g)}{\sum_{i\in sample}count(i)/size(i)} 
\end{equation}
$$ {#eq-tpm}

See @zhaoMisuseRPKMTPM2020 for discussion of the transcripts per million
normalisation and for references to more papers about RNA sequencing
experiments.

For use in imodulon analysis further transformations are performed. First the
transcripts per million are put on log scale, then the log-transcripts per
million of a reference condition are subtracted. Finally the data are whitened
using scikit-learn's `arbitrary-variance` option.

# Our project

## Why we want to attempt a Bayesian Imodulon analysis

There are several general reasons to prefer Bayesian ICA models to models that
use a maximum likelihood approach, including automatic relevance detection, the
potential to take into account quantitative non-measurement information through
a prior model, and the avoidance of pathological model behaviour due to bad or
incomplete observations. These general reasons are discussed in
@robertsBayesianIndependentComponent2005.

These advantages are particularly pertinent for the application of ICA to
attempting to infer Imodulons from RNA sequencing data. 

First, as described in @robertsBayesianIndependentComponent2005, a Bayesian ICA
model can potentially use automatic relevance detection to find an appropriate
number of Imodulons to postulate. Whereas in the current framework the
appropriate number of Imodulons is determined using a procedure that is
separate from the main inference and motivated by computational and algorithmic
considerations---primarily whether the algorithm successfully
converges---rather than substantive statistical ones, relevance detection based
on hyperparameters in the context of a Bayesian model is well-motivated and
does not require downstream processing.

Second, there is substantial non-experimental information about Imodulons that
should provide important context to RNA sequencing measurements. In particular,
as discussed above investigation of regulons and transcription factors suggests
that an Imodulon should typically affect a relatively small number of genes.
Maximum-likelihood based Imodulon analysis uses another
non-statistically-motivated downstream procedure to impose this sparsity after
fitting an ICA model. We would like to represent this information in a Bayesian
ICA model by using a sparsity-inducing prior for the columns of the mixing
matrix $M$. 

Another potential source of non-experimental information is the research into
regulons and transcription factors itself. Many genes, particularly those in a
species's 'core' genome that are common to almost all strains, are known in
advance to share specific regulators, and this information can be taken into
account in a Bayesian framework through informative priors on specific elements
of the mixing matrix $M$.

Finally, the robustness gained by using a Bayesian statistical analysis is
likely to be helpful when attempting to infer Imodulons for species with fewer
RNA sequencing experiments.

## What we would like to achieve

Ultimately we would like to create a sparse Bayesian ICA model that can
reproduce the analysis in @tanIndependentComponentAnalysis2020 of the
precise-db dataset. This analysis inferred 92 Imodulons from RNA sequencing
measurements of 4386 genes in 278 conditions. We would then like to use the
same approach to analyse RNA sequencing data from organisms with fewer
measurements and to augment our model with informative priors based on
information about regulons.

As a proof of concept we would like to generate and then fit a smaller
artificial dataset with uninformative but still sparsity-inducing priors, then
fit the same model to a subset of the precise-db dataset.

## Model

In contrast to the model in @hyvarinenIndependentComponentAnalysis2000 and
previous Imodulon analyses we propose to include measurement noise in our
statistical model. Although it would perhaps be preferable to model the whole
data generation process up to the production of untransformed raw counts, for
the sake of simplicity and easier comparison with previous approaches we will
use the following simple linear regression model for transformed RNA sequencing
data, assuming known measurement error $\sigma$:

$$
\begin{equation*}
y \sim N(\hat{y}, \sigma)
\end{equation*}
$$ {#eq-noise-likelihood}

In order to ensure that our model implements ICA we will use a column-wise
independent and row-wise non-Gaussian prior distribution for the source
strength matrix $A$:

$$
\begin{equation*}
a_kj \sim T4(0,1)
\end{equation*}
$$ {#eq-source-model}

In @eq-source-model $T4$ refers to the student-t distribution with 4
degrees of freedom. The use of a unit scale for each row is beause ICA models
are identified only up to a change of scale

We will use independent regularised horseshoe priors for the columns of the
mixing matrix $M$:

$$
\begin{align*}
m_{ik} &\sim N^+(0, \tau_k\tilde{\lambda}_{ik}) \\
\tilde{\lambda}_{ik})^2 &= \frac{c_k^2\lambda_{ik}^2}{c_k^2 + \tau_k^2\lambda_{ik}^2} \\
\lambda_{ik} &\sim C^+(0, 1) \\
c_k^2 &\sim \text{inverse gamma}(\alpha, \beta) \\
\tau_k &\sim C^+(0, \tau_{k0})
\end{align*}
$$ {#eq-mixing-model}

In @eq-mixing-model $C^+$ and $N^+$ refer respectively to Cauchy and
Normal distributions with support only on the positive real line, and the terms
$alpha$, $\beta$ and $tau_{k0}$ are informative priors. Note that the mixing
matrix prior is constrained to have support only on the non-negative real line.
This is done, following @robertsBayesianIndependentComponent2005, to ensure
sign consistency, so that a positive relative change in an Imodulon's strength
in a certain condition will always correspond to up-regulation of genes
affected by that Imodulon.

# Where we need help

We need to address a few statistical programming issues as we have not yet
managed to implement our target model:

* Is it feasible to fit our target model and dataset with Stan, or should we
  try a different framework (or give up, try a simpler model etc)? What would
  be good potential options for simpler models or alternative frameworks?

* What is the right way to implement the regularised horseshoe prior for this
  case?
